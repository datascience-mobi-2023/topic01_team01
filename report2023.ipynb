{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face recognition\n",
    "\n",
    "## Authors: Sera Kaplan, Sarah Manderschied, Lejla Mesic, Emilia Thiel\n",
    "\n",
    "## July 2023\n",
    "\n",
    "## Abstract\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "**1. Introduction**\n",
    "\n",
    "**2. Our Dataset**\n",
    "\n",
    "**3. Methods**\n",
    "\n",
    " **3.1 z-transformation**\n",
    "\n",
    " **3.2 Implementing Principle component analysis (PCA) algorithm**\n",
    "\n",
    " **3.3 Implementing K-nearest neighbors (KNN) algorithm**\n",
    "\n",
    "**4. Results**\n",
    "\n",
    "**4.1 Data split**\n",
    "\n",
    "**4.2 PCA**\n",
    "\n",
    "**4.3 KNN**\n",
    "\n",
    "**5. Discussion**\n",
    "\n",
    "**6. Further application**\n",
    "\n",
    "**7. References**\n",
    "\n",
    "## Introduction\n",
    "\n",
    "## Our dataset\n",
    "\n",
    "## Methods\n",
    "\n",
    "### z-transformation\n",
    "\n",
    "z-Transformation, also known as standardization or normalization, is a statistical technique used to transform a distribution by subtracting the mean and dividing by the standard deviation. The purpose is to standardize the data so that it has a mean of 0 and a standard deviation of 1. In this project, the z-transformation is applied to the feature vectors representing the facial images. Before applying z- transformation to a matrix of pixel values, it was important to flatten the 2D image into a 1D array and assign it to pixel values, which were stored in one list. After all pixel values from all images are combined and stored into a list, it was transformed into a matrix. Z-Transformation calculates standard deviation for each row in that matrix and if the standard deviation is zero, it subtracts the mean from the row, if not, it calculates the mean of the row and performs z-transformation by subtracting the mean and dividing by the standard deviation. After performing all rows in the input ‘Matrix’ the transformed matrix is returned.\n",
    "\n",
    "### Implementing Principle component analysis (PCA) algorithm\n",
    "\n",
    "PCA is a popular dimensionality reduction technique used to reduce the number of features in a dataset while preserving the most important information. In this project, the PCA class was imported and used from the scikit-learn library. The **fit ()** method of the PCA is called to fit the model to the transformed data obtained from the z-transformation. **Transform ()** method was used to project the data onto the lower-dimensional space defined by the principal components. The resulting transformed data that contains the new feature vector in the reduced dimensional space is used for further modeling tasks.\n",
    "\n",
    "### Implementing K-nearest neighbors (KNN) algorithm\n",
    "\n",
    "The k-nearest neighbors algorithm, also known as KNN or k-NN, is a non-parametric, supervised learning classifier, which uses proximity to make classifications or predictions about the grouping of an individual data point **Quelle1**  \n",
    "It is one of the simplest machine learning algorithms that makes predictions based on the similarity of input data to its neighboring samples. In this project the KNN algorithm was utilized to match and classify faces. The “KNeighborsClassifier” class from the scikit-learn library was imported and used to create an KNN classifier **Quelle2**. \n",
    "As parameters, k value was determined, but also other values according to sklearn such as:\n",
    "*\tWeights: which was set to ‘distance’ to give more weight to closer neighbors, \n",
    "*\tAlgorithm: which was set to ‘auto’ to attempt to decide the most appropriate algorithm based on the values passed to fit method\n",
    "*\tMetric: which was set to ‘manhattan’ for distance calculation using Manhattan distance $$ (\\sum_{i=1}^{k}{|xi-yi|}) $$\n",
    "*\tleaf size: which was set to 30 (default) for efficient tree construction\n",
    "\n",
    "After that, KNN classifier was trained using the transformed data, which represents the feature vectors of the training dataset and corresponding labels of the individuals in the training set. During training, the KNN classifier learns the patterns and relationships between the transformed data and their corresponding labels. The classifier uses the training data to build an internal representation or model that allows it to make predictions on test data. The dataset that represents the feature vectors of the test faces is transformed using the same PCA transformation used for the training data. This transformation ensures consistency in the feature representation between the training and test dataset. The transformed test data was then passed to the KNN classifier’s predict () method, which utilizes the trained model to predict the identities or labels of the test faces.\n",
    "\n",
    "### UML class diagram\n",
    "\n",
    "\n",
    "## Results\n",
    " \n",
    "### Data split\n",
    "\n",
    "### PCA\n",
    "\n",
    "### KNN\n",
    "\n",
    "## Discussion\n",
    "\n",
    "## Further application\n",
    "\n",
    "## References"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
